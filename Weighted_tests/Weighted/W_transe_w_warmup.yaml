dataset:
  name: wnrr
eval:
  
  batch_size: 256
  metrics_per:
    relation_type: true
  trace_level: example
import:
- W_transe
- reciprocal_relations_model
- final_W_negative_sampling
lookup_embedder:
  dim: 512
  initialize: xavier_normal_
  initialize_args:
    normal_:
      mean: 0.0
      std: 0.00036174939032954854
    uniform_:
      a: -0.393658811201549
    xavier_normal_:
      gain: 1.0
    xavier_uniform_:
      gain: 1.0
model: reciprocal_relations_model
final_W_negative_sampling:
  num_samples:
    o: 158
    p: -1
    s: 70
reciprocal_relations_model:
  base_model:
    type: W_transe
train:
  auto_correct: true
  batch_size: 128
  loss: W_kl
  loss_arg: 1.0
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_args:
    factor: 0.95
    mode: max
    patience: 5
    threshold: 0.0001
  max_epochs: 400
  optimizer_args:
    lr: 0.2532720169185861
  type: final_W_negative_sampling
W_transe:
  entity_embedder:
    pretrain:
      model_filename: local/experiments/20220915-142007-Transe_w/checkpoint_best.pt
    dropout: 0.2519204934424376
    normalize:
      p: -1.0
    regularize_weight: 2.1299293567133326e-07
  l_norm: 2.0
  relation_embedder:
    pretrain:
      model_filename: local/experiments/20220915-142007-Transe_w/checkpoint_best.pt
    dropout: -0.025948206777731686
    normalize:
      p: -1.0
    regularize_weight: 8.992034045083661e-13
  clip: 20
  init: False
  require_grad_relation: False
  require_grad_entity: True
  golden_ratio: 0.2
valid:
  early_stopping:
    min_threshold:
      epochs: 50
      metric_value: 0.05
    patience: 10
  every: 1
